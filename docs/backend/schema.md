# Data Schema (PostgreSQL)

The application's data layer is built on **PostgreSQL**. The schema is designed to balance **relational integrity** (ensuring every report belongs to a valid user) with **NoSQL flexibility** (storing complex sensor data in JSON format).

This hybrid approach allows us to add new metrics (like a new "GPU Temp" sensor) without needing to rewrite the entire database structure.

---

## ðŸ—‚ Core Tables

The database is organized into four primary domains:

### 1. Identity & Devices
These tables manage *who* owns the data and *where* it comes from.

* **`profiles`**: Extensions of the standard Supabase User.
    * `id` (UUID): Links directly to `auth.users`.
    * `email`: User's contact info.
    * `preferences`: JSON blob for dashboard settings (e.g., Dark Mode toggle).

* **`devices`**: A registry of physical machines.
    * `device_id` (UUID): Unique hardware identifier generated by the Desktop Agent.
    * `user_id` (UUID): The owner of the device.
    * `specs`: JSONB column storing static hardware info (CPU model, Total RAM).
    * `last_seen`: Timestamp of the last successful heartbeat.

### 2. Telemetry (Time-Series Data)
This is the heaviest table in the system, receiving uploads every few minutes.

* **`system_metrics`**: The log of historical performance.
    * `id`: Primary Key.
    * `device_id`: Foreign Key to `devices`.
    * `timestamp`: When the data was captured.
    * `cpu_avg`: Fast-access column for querying.
    * `ram_percent`: Fast-access column for querying.
    * `raw_data`: **JSONB**. Contains the full, granular report from `psutil`.

> **Why JSONB?** By storing the bulk of the data in a JSONB column, we can query specific fields (like `raw_data->'sensors'->'fan_speed'`) if we need them, but we don't need to create a dedicated column for every single sensor on the motherboard.

### 3. Intelligence & Alerts
Stores the outputs of the Machine Learning and Agentic engines.

* **`anomalies`**: Events flagged by the Local ML Engine.
    * `severity`: "Critical", "Warning", or "Info".
    * `anomaly_type`: e.g., "Thermal Throttling".
    * `description`: Human-readable explanation.

* **`chat_history`**: Persistent memory for the AI Agent.
    * `session_id`: specific conversation thread.
    * `role`: "user" or "assistant".
    * `content`: The actual text of the message.

---

## ðŸ§  Vector Store (RAG Schema)

To support the **Retrieval-Augmented Generation (RAG)** pipeline, we use the `pgvector` extension.

* **`documentation_embeddings`**:
    * `id`: Unique ID.
    * `content`: The actual text chunk (e.g., a paragraph from the Arch Linux wiki).
    * `embedding`: A `vector(1536)` column. This stores the 1,536-dimensional coordinate representing the *meaning* of the text.

---

## ðŸ”— Relationships (ER Diagram)

The data flows hierarchically:

1.  A **User** has many **Devices**.
2.  A **Device** produces many **Metrics**.
3.  A **Device** can have many **Anomalies**.

```sql
-- Simplified Relationship Logic
users (1) â”€â”€â”€â”€< devices (N)
                   â”‚
                   â”œâ”€â”€â”€â”€< system_metrics (N)
                   â””â”€â”€â”€â”€< anomalies (N)
```

## ðŸ›¡ Data Retention Policies
To prevent the database from growing infinitely (since telemetry generates massive amounts of data), we implement a Cron Job (via pg_cron in Supabase).

High Resolution: Keep raw data for 7 days.

Medium Resolution: After 7 days, average the data into 1-hour chunks.

Low Resolution: After 30 days, average the data into 1-day chunks.

Purge: Delete data older than 1 year.